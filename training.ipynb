{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2d9340-5c89-4e54-84f7-424c348f414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from dataset import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import csv\n",
    "from unet import UNet, UNetL, UNetLL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c737dc34-d9d2-43e2-a6a9-3361b0462cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(preds, targets, threshold=0.5, eps=1e-6):\n",
    "    preds = torch.sigmoid(preds)\n",
    "    preds = (preds > threshold).float()\n",
    "    intersection = (preds * targets).sum(dim=(1, 2, 3))\n",
    "    union = preds.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3)) - intersection\n",
    "    return ((intersection + eps) / (union + eps)).mean()\n",
    "\n",
    "def precision_score(preds, targets, threshold=0.5, eps=1e-6):\n",
    "    preds = torch.sigmoid(preds)\n",
    "    preds = (preds > threshold).float()\n",
    "    true_positive = (preds * targets).sum()\n",
    "    predicted_positive = preds.sum()\n",
    "    return (true_positive + eps) / (predicted_positive + eps)\n",
    "\n",
    "def recall_score(preds, targets, threshold=0.5, eps=1e-6):\n",
    "    preds = torch.sigmoid(preds)\n",
    "    preds = (preds > threshold).float()\n",
    "    true_positive = (preds * targets).sum()\n",
    "    actual_positive = targets.sum()\n",
    "    return (true_positive + eps) / (actual_positive + eps)\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        probs = probs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (probs * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (\n",
    "            probs.sum() + targets.sum() + self.smooth\n",
    "        )\n",
    "\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a44c17d-a4d5-46e3-8ee8-031c6fc42583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "Used a fraction of 1.0 GPU's memory\n",
      "Weighted BCE:\tTrue\n",
      "Tiles Dimension: 256x256\n",
      "Training dataset dimension: 56000\n",
      "Validation dataset dimension: 4000\n",
      "1750 batches of 32 images\n",
      "Computing the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 56000/56000 [01:38<00:00, 569.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive weight:\t5.54\n",
      "\n",
      "GPU ID: 0\n",
      "GPU Total Memory: 47.53 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_1293701/2432085640.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  weight = torch.tensor(neg_freq / pos_freq)\n"
     ]
    }
   ],
   "source": [
    "starting_time = time.time()\n",
    "\n",
    "architecture_name = 'unetLL'\n",
    "model_dataset = 'WHU'\n",
    "dataset_kind = 'WHUBuildingDataset'\n",
    "tile_dimension = 256\n",
    "batch_size = 32\n",
    "weightedBCE = True\n",
    "diceLoss = True\n",
    "earlystop = False\n",
    "\n",
    "# Initial setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = 'cpu'\n",
    "print(f\"Device: {device}\\n\")\n",
    "memory_fraction = 1.\n",
    "print(f\"Used a fraction of {memory_fraction} GPU's memory\")\n",
    "print(f\"Weighted BCE:\\t{weightedBCE}\")\n",
    "\n",
    "training_dataset_portion = 1\n",
    "validation_dataset_portion = 0.5\n",
    "num_epochs = 30\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 5\n",
    "early_stop_counter = 0\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset_path = '/mnt/nas151/sar/Footprint/datasets/'\n",
    "\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset_full = MyDataset(image_dir=dataset_path + dataset_kind + f'/tiles_{tile_dimension}/train/images',\n",
    "                          mask_dir=dataset_path + dataset_kind + f'/tiles_{tile_dimension}/train/gt',\n",
    "                          transform=transform)\n",
    "\n",
    "# In order to train with fewer images, this part will mix and select a portion (dataset_portion) of the entire training dataset.\n",
    "num_samples = len(train_dataset_full)\n",
    "subset_size = int(training_dataset_portion * num_samples)\n",
    "indices = np.random.permutation(num_samples)[:subset_size]\n",
    "train_dataset = Subset(train_dataset_full, indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset_full = MyDataset(image_dir=dataset_path + dataset_kind + f'/tiles_{tile_dimension}/val/images',\n",
    "                          mask_dir=dataset_path + dataset_kind + f'/tiles_{tile_dimension}/val/gt',\n",
    "                          transform=transform)\n",
    "\n",
    "# In order to train with fewer images, this part will mix and select a portion (dataset_portion) of the entire training dataset.\n",
    "num_samples = len(val_dataset_full)\n",
    "subset_size = int(validation_dataset_portion * num_samples)\n",
    "indices = np.random.permutation(num_samples)[:subset_size]\n",
    "val_dataset = Subset(val_dataset_full, indices)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "tot_batches = int(len(train_dataset)/batch_size)\n",
    "\n",
    "print(f\"Tiles Dimension: {tile_dimension}x{tile_dimension}\")\n",
    "\n",
    "print(f'Training dataset dimension: {len(train_dataset)}')\n",
    "print(f'Validation dataset dimension: {len(val_dataset)}')\n",
    "\n",
    "print(f\"{tot_batches} batches of {batch_size} images\")\n",
    "\n",
    "if weightedBCE:\n",
    "    '''start = time.time()\n",
    "    print('Computing the weights...')\n",
    "    tile_length = len(train_loader.dataset[0][1][0]) * len(train_loader.dataset[0][1][0][0])\n",
    "    pos_freq = 0\n",
    "    neg_freq = 0\n",
    "    for tile in tqdm(train_loader.dataset):\n",
    "        pos_freq += torch.sum(tile[1][0])\n",
    "\n",
    "    neg_freq = tile_length * len(train_loader.dataset) - pos_freq\n",
    "    pos_weight = neg_freq / (tile_length * len(train_loader.dataset))\n",
    "    neg_weight = pos_freq / (tile_length * len(train_loader.dataset))\n",
    "\n",
    "    print(f'Positive weight:\\t{pos_weight}\\nNegative weight:\\t{neg_weight}')\n",
    "    weight = torch.tensor([pos_weight, neg_weight])\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight.to(device), size_average=None, reduce=None, reduction='mean')'''\n",
    "    loss_name = 'WBCE'\n",
    "    # First attempt. I need to change for the frequency of buildings and background pixels\n",
    "    start = time.time()\n",
    "    print('Computing the weights...')\n",
    "    tile_length = len(train_loader.dataset[0][1][0]) * len(train_loader.dataset[0][1][0][0])\n",
    "    pos_freq = 0\n",
    "    neg_freq = 0\n",
    "    for tile in tqdm(train_loader.dataset):\n",
    "        pos_freq += torch.sum(tile[1][0])\n",
    "\n",
    "    neg_freq = tile_length * len(train_loader.dataset) - pos_freq\n",
    "    weight = torch.tensor(neg_freq / pos_freq)\n",
    "    print(f'Positive weight:\\t{weight:.2f}')\n",
    "    bce_criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "else:\n",
    "    loss_name = 'BCE'\n",
    "    bce_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "if diceLoss:\n",
    "    loss_name += 'plusDL'\n",
    "    dice_criterion = DiceLoss()\n",
    "else:\n",
    "    dice_criterion = None\n",
    "# model initialization, loss and optimizer\n",
    "if architecture_name == 'unet':\n",
    "    model = UNet(n_channels=3, n_classes=1).to(device)\n",
    "elif architecture_name == 'unetL':\n",
    "    model = UNetL(n_channels=3, n_classes=1).to(device)\n",
    "elif architecture_name == 'unetLL':\n",
    "    model = UNetLL(n_channels=3, n_classes=1).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.01, total_iters=20)\n",
    "\n",
    "model_name = f'{architecture_name}_{model_dataset}_{loss_name}_n{len(train_dataset)}_dim{tile_dimension}x{tile_dimension}_bs{batch_size}'\n",
    "os.makedirs(f'/home/antoniocorvino/Projects/BuildingsExtraction/runs/{model_name}', exist_ok=True)\n",
    "\n",
    "# Saving metrics\n",
    "csv_metrics = f\"/home/antoniocorvino/Projects/BuildingsExtraction/runs/{model_name}/metrics.csv\"\n",
    "\n",
    "with open(csv_metrics, mode='w', newline='') as f:\n",
    "    writer_csv = csv.writer(f)\n",
    "    writer_csv.writerow([\"epoch\",\n",
    "                         \"train_epoch_loss\", \"train_iou\", \"train_precision\", \"train_recall\",\n",
    "                         \"val_epoch_loss\", \"val_iou\", \"val_precision\", \"val_recall\",\n",
    "                         \"time\"])\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_id = torch.cuda.current_device()\n",
    "    print(f\"\\nGPU ID: {gpu_id}\")\n",
    "    print(f\"GPU Total Memory: {torch.cuda.get_device_properties(gpu_id).total_memory/1024**3:.2f} GB\")\n",
    "    torch.cuda.set_per_process_memory_fraction(memory_fraction, device=gpu_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f06ce19d-13f2-413e-aa62-a562533bc588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH ---- 1/30\n",
      "Current Learning Rate: 0.001000\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.09 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:27\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "0.45841444277763366 0\n",
      "\n",
      "Time for Validation: 37s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.5031\tIoU: 0.4985\tPrecision: 0.5551\tRecall: 0.8902\n",
      "VALIDATION\tLoss: 0.4584\tIoU: 0.5985\tPrecision: 0.6944\tRecall: 0.8120\n",
      "\n",
      "\n",
      "EPOCH ---- 2/30\n",
      "Current Learning Rate: 0.000951\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:29\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "0.36991091406345367 1\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.3898\tIoU: 0.5697\tPrecision: 0.6258\tRecall: 0.9193\n",
      "VALIDATION\tLoss: 0.3699\tIoU: 0.5209\tPrecision: 0.5784\tRecall: 0.9321\n",
      "\n",
      "\n",
      "EPOCH ---- 3/30\n",
      "Current Learning Rate: 0.000901\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:29\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "0.34991849517822265 2\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.3488\tIoU: 0.5995\tPrecision: 0.6532\tRecall: 0.9288\n",
      "VALIDATION\tLoss: 0.3499\tIoU: 0.6578\tPrecision: 0.6957\tRecall: 0.8899\n",
      "\n",
      "\n",
      "EPOCH ---- 4/30\n",
      "Current Learning Rate: 0.000852\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:31\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "0.3106054857969284 3\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.3242\tIoU: 0.6198\tPrecision: 0.6718\tRecall: 0.9347\n",
      "VALIDATION\tLoss: 0.3106\tIoU: 0.6246\tPrecision: 0.6688\tRecall: 0.9306\n",
      "\n",
      "\n",
      "EPOCH ---- 5/30\n",
      "Current Learning Rate: 0.000802\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:26\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.3069\tIoU: 0.6350\tPrecision: 0.6859\tRecall: 0.9386\n",
      "VALIDATION\tLoss: 0.3415\tIoU: 0.5534\tPrecision: 0.5854\tRecall: 0.9503\n",
      "\n",
      "\n",
      "EPOCH ---- 6/30\n",
      "Current Learning Rate: 0.000753\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:28\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2936\tIoU: 0.6442\tPrecision: 0.6937\tRecall: 0.9421\n",
      "VALIDATION\tLoss: 0.3575\tIoU: 0.5420\tPrecision: 0.5747\tRecall: 0.9479\n",
      "\n",
      "\n",
      "EPOCH ---- 7/30\n",
      "Current Learning Rate: 0.000703\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:28\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "0.29318719398975374 6\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2805\tIoU: 0.6552\tPrecision: 0.7052\tRecall: 0.9447\n",
      "VALIDATION\tLoss: 0.2932\tIoU: 0.6359\tPrecision: 0.6910\tRecall: 0.9317\n",
      "\n",
      "\n",
      "EPOCH ---- 8/30\n",
      "Current Learning Rate: 0.000654\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:30\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "0.27528381192684176 7\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2714\tIoU: 0.6613\tPrecision: 0.7113\tRecall: 0.9473\n",
      "VALIDATION\tLoss: 0.2753\tIoU: 0.6654\tPrecision: 0.7116\tRecall: 0.9341\n",
      "\n",
      "\n",
      "EPOCH ---- 9/30\n",
      "Current Learning Rate: 0.000604\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:27\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2606\tIoU: 0.6691\tPrecision: 0.7174\tRecall: 0.9499\n",
      "VALIDATION\tLoss: 0.2858\tIoU: 0.6609\tPrecision: 0.6990\tRecall: 0.9303\n",
      "\n",
      "\n",
      "EPOCH ---- 10/30\n",
      "Current Learning Rate: 0.000555\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:29\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2529\tIoU: 0.6731\tPrecision: 0.7227\tRecall: 0.9517\n",
      "VALIDATION\tLoss: 0.2810\tIoU: 0.6944\tPrecision: 0.7353\tRecall: 0.9198\n",
      "\n",
      "\n",
      "Checkpoint 10\n",
      "EPOCH ---- 11/30\n",
      "Current Learning Rate: 0.000505\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:29\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "0.26616266250610354 10\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2448\tIoU: 0.6805\tPrecision: 0.7283\tRecall: 0.9541\n",
      "VALIDATION\tLoss: 0.2662\tIoU: 0.6706\tPrecision: 0.7134\tRecall: 0.9378\n",
      "\n",
      "\n",
      "EPOCH ---- 12/30\n",
      "Current Learning Rate: 0.000456\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:30\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "0.26557104671001436 11\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2370\tIoU: 0.6845\tPrecision: 0.7337\tRecall: 0.9561\n",
      "VALIDATION\tLoss: 0.2656\tIoU: 0.6848\tPrecision: 0.7208\tRecall: 0.9340\n",
      "\n",
      "\n",
      "EPOCH ---- 13/30\n",
      "Current Learning Rate: 0.000406\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:30\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2300\tIoU: 0.6897\tPrecision: 0.7383\tRecall: 0.9580\n",
      "VALIDATION\tLoss: 0.2662\tIoU: 0.6903\tPrecision: 0.7248\tRecall: 0.9335\n",
      "\n",
      "\n",
      "EPOCH ---- 14/30\n",
      "Current Learning Rate: 0.000357\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:28\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "0.26308364498615266 13\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2228\tIoU: 0.6945\tPrecision: 0.7436\tRecall: 0.9598\n",
      "VALIDATION\tLoss: 0.2631\tIoU: 0.6548\tPrecision: 0.6888\tRecall: 0.9487\n",
      "\n",
      "\n",
      "EPOCH ---- 15/30\n",
      "Current Learning Rate: 0.000307\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:29\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2173\tIoU: 0.6966\tPrecision: 0.7470\tRecall: 0.9613\n",
      "VALIDATION\tLoss: 0.2694\tIoU: 0.6910\tPrecision: 0.7347\tRecall: 0.9322\n",
      "\n",
      "\n",
      "EPOCH ---- 16/30\n",
      "Current Learning Rate: 0.000258\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:28\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2100\tIoU: 0.7016\tPrecision: 0.7534\tRecall: 0.9630\n",
      "VALIDATION\tLoss: 0.2682\tIoU: 0.6986\tPrecision: 0.7413\tRecall: 0.9310\n",
      "\n",
      "\n",
      "EPOCH ---- 17/30\n",
      "Current Learning Rate: 0.000208\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:24\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.2035\tIoU: 0.7043\tPrecision: 0.7583\tRecall: 0.9646\n",
      "VALIDATION\tLoss: 0.2638\tIoU: 0.6800\tPrecision: 0.7253\tRecall: 0.9381\n",
      "\n",
      "\n",
      "EPOCH ---- 18/30\n",
      "Current Learning Rate: 0.000159\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:29\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1990\tIoU: 0.7084\tPrecision: 0.7610\tRecall: 0.9659\n",
      "VALIDATION\tLoss: 0.2669\tIoU: 0.6794\tPrecision: 0.7275\tRecall: 0.9390\n",
      "\n",
      "\n",
      "EPOCH ---- 19/30\n",
      "Current Learning Rate: 0.000109\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:28\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1943\tIoU: 0.7111\tPrecision: 0.7646\tRecall: 0.9671\n",
      "VALIDATION\tLoss: 0.2860\tIoU: 0.6986\tPrecision: 0.7443\tRecall: 0.9297\n",
      "\n",
      "\n",
      "EPOCH ---- 20/30\n",
      "Current Learning Rate: 0.000060\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:31\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1903\tIoU: 0.7155\tPrecision: 0.7683\tRecall: 0.9680\n",
      "VALIDATION\tLoss: 0.2793\tIoU: 0.6926\tPrecision: 0.7365\tRecall: 0.9332\n",
      "\n",
      "\n",
      "Checkpoint 20\n",
      "EPOCH ---- 21/30\n",
      "Current Learning Rate: 0.000010\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:31\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1874\tIoU: 0.7189\tPrecision: 0.7700\tRecall: 0.9689\n",
      "VALIDATION\tLoss: 0.2812\tIoU: 0.6914\tPrecision: 0.7387\tRecall: 0.9325\n",
      "\n",
      "\n",
      "EPOCH ---- 22/30\n",
      "Current Learning Rate: 0.000010\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:29\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1868\tIoU: 0.7183\tPrecision: 0.7710\tRecall: 0.9689\n",
      "VALIDATION\tLoss: 0.2827\tIoU: 0.6876\tPrecision: 0.7394\tRecall: 0.9321\n",
      "\n",
      "\n",
      "EPOCH ---- 23/30\n",
      "Current Learning Rate: 0.000010\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:29\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1862\tIoU: 0.7189\tPrecision: 0.7717\tRecall: 0.9691\n",
      "VALIDATION\tLoss: 0.2826\tIoU: 0.6872\tPrecision: 0.7398\tRecall: 0.9328\n",
      "\n",
      "\n",
      "EPOCH ---- 24/30\n",
      "Current Learning Rate: 0.000010\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:28\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1863\tIoU: 0.7191\tPrecision: 0.7712\tRecall: 0.9690\n",
      "VALIDATION\tLoss: 0.2830\tIoU: 0.6877\tPrecision: 0.7406\tRecall: 0.9325\n",
      "\n",
      "\n",
      "EPOCH ---- 25/30\n",
      "Current Learning Rate: 0.000010\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:27\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1859\tIoU: 0.7184\tPrecision: 0.7716\tRecall: 0.9691\n",
      "VALIDATION\tLoss: 0.2889\tIoU: 0.6936\tPrecision: 0.7455\tRecall: 0.9300\n",
      "\n",
      "\n",
      "EPOCH ---- 26/30\n",
      "Current Learning Rate: 0.000010\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:30\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1857\tIoU: 0.7181\tPrecision: 0.7717\tRecall: 0.9692\n",
      "VALIDATION\tLoss: 0.2876\tIoU: 0.6853\tPrecision: 0.7415\tRecall: 0.9315\n",
      "\n",
      "\n",
      "EPOCH ---- 27/30\n",
      "Current Learning Rate: 0.000010\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:29\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1858\tIoU: 0.7183\tPrecision: 0.7720\tRecall: 0.9691\n",
      "VALIDATION\tLoss: 0.2886\tIoU: 0.6924\tPrecision: 0.7396\tRecall: 0.9319\n",
      "\n",
      "\n",
      "EPOCH ---- 28/30\n",
      "Current Learning Rate: 0.000010\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:31\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1854\tIoU: 0.7195\tPrecision: 0.7719\tRecall: 0.9693\n",
      "VALIDATION\tLoss: 0.2856\tIoU: 0.6875\tPrecision: 0.7410\tRecall: 0.9320\n",
      "\n",
      "\n",
      "EPOCH ---- 29/30\n",
      "Current Learning Rate: 0.000010\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:31\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1852\tIoU: 0.7197\tPrecision: 0.7721\tRecall: 0.9693\n",
      "VALIDATION\tLoss: 0.2889\tIoU: 0.6941\tPrecision: 0.7415\tRecall: 0.9309\n",
      "\n",
      "\n",
      "EPOCH ---- 30/30\n",
      "Current Learning Rate: 0.000010\n",
      "\n",
      "Training is started...\n",
      "\n",
      "Memory Allocated: 0.10 GB\n",
      "Memory Reserved: 1.29 GB\n",
      "Progress: 100% -- time: 04:30\n",
      "\n",
      "\n",
      "Validation is started...\n",
      "\n",
      "Time for Validation: 12s\n",
      "\n",
      "\n",
      "TRAINING\tLoss: 0.1850\tIoU: 0.7191\tPrecision: 0.7721\tRecall: 0.9694\n",
      "VALIDATION\tLoss: 0.2848\tIoU: 0.6900\tPrecision: 0.7402\tRecall: 0.9328\n",
      "\n",
      "\n",
      "Checkpoint 30\n",
      "Total time: 143.32 minutes\n"
     ]
    }
   ],
   "source": [
    "best_loss = 1e4\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"EPOCH ---- {epoch+1}/{num_epochs}\")\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'Current Learning Rate: {current_lr:.6f}')\n",
    "    print(\"\\nTraining is started...\\n\")\n",
    "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(gpu_id)/1024**3:.2f} GB\")\n",
    "    print(f\"Memory Reserved: {torch.cuda.memory_reserved(gpu_id)/1024**3:.2f} GB\")\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "\n",
    "    epoch_train_loss = 0.0\n",
    "    batch_number = 0\n",
    "    iou_total = 0.0\n",
    "    prec_total = 0.0\n",
    "    recall_total = 0.0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        \n",
    "        batch_number += 1\n",
    "\n",
    "        #print(f\"\\nBatch #{batch_number}\")\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).float()  # This must be \"float\" for the loss function\n",
    "\n",
    "        #print(f\"Memory allocated by the batch: {torch.cuda.memory_allocated(gpu_id)/1024**2:.2f} MB\")\n",
    "        #print(f\"Memory reserved by the batch: {torch.cuda.memory_reserved(gpu_id)/1024**2:.2f} MB\")\n",
    "        #batch_memory = images.element_size() * images.nelement() + masks.element_size() * masks.nelement()\n",
    "        #print(f\"Memory occupied by the batch (images and masks only): {batch_memory / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        if dice_criterion:\n",
    "            loss = bce_criterion(outputs, masks)\n",
    "        else:\n",
    "            loss = bce_criterion(outputs, masks)\n",
    "        with torch.no_grad():\n",
    "            iou_batch = iou_score(outputs, masks)\n",
    "            prec_batch = precision_score(outputs, masks)\n",
    "            recall_batch = recall_score(outputs, masks)\n",
    "\n",
    "        iou_total += iou_batch\n",
    "        prec_total += prec_batch\n",
    "        recall_total += recall_batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        if batch_number % int(0.1 * tot_batches) == 0:\n",
    "            print(f\"\\rProgress: {(100 * batch_number/tot_batches):.0f}% -- time: {int(elapsed_time//60):02d}:{int(elapsed_time%60):02d}\", end=\"\")\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_train_loss /= len(train_loader)\n",
    "\n",
    "    train_iou = (iou_total / len(train_loader)).item()\n",
    "    train_prec = (prec_total / len(train_loader)).item()\n",
    "    train_recall = (recall_total / len(train_loader)).item()\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"\\nValidation is started...\")\n",
    "\n",
    "    # --- VALIDATION STEP ---\n",
    "    starting_val = time.time()\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    val_iou = 0.0\n",
    "    val_prec = 0.0\n",
    "    val_recall = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_masks in val_loader:\n",
    "            val_images = val_images.to(device)\n",
    "            val_masks = val_masks.to(device).float()\n",
    "\n",
    "            val_outputs = model(val_images)\n",
    "            loss_val = bce_criterion(val_outputs, val_masks)\n",
    "            epoch_val_loss += loss_val.item()\n",
    "\n",
    "            val_iou += iou_score(val_outputs, val_masks)\n",
    "            val_prec += precision_score(val_outputs, val_masks)\n",
    "            val_recall += recall_score(val_outputs, val_masks)\n",
    "\n",
    "    # Average validation metrics\n",
    "    epoch_val_loss /= len(val_loader)\n",
    "    val_iou = (val_iou / len(val_loader)).item()\n",
    "    val_prec = (val_prec / len(val_loader)).item()\n",
    "    val_recall = (val_recall / len(val_loader)).item()\n",
    "\n",
    "    if epoch_val_loss < best_loss:\n",
    "        best_loss = epoch_val_loss\n",
    "        print(best_loss, epoch)\n",
    "        torch.save(model.state_dict(), f\"/home/antoniocorvino/Projects/BuildingsExtraction/runs/{model_name}/best_model.pth\")\n",
    "\n",
    "    \n",
    "    print(f\"\\nTime for Validation: {int(time.time() - starting_val):02d}s\\n\")\n",
    "\n",
    "    print(f'\\nTRAINING\\tLoss: {epoch_train_loss:.4f}\\tIoU: {train_iou:.4f}\\tPrecision: {train_prec:.4f}\\tRecall: {train_recall:.4f}')\n",
    "    print(f\"VALIDATION\\tLoss: {epoch_val_loss:.4f}\\tIoU: {val_iou:.4f}\\tPrecision: {val_prec:.4f}\\tRecall: {val_recall:.4f}\\n\\n\")\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    with open(csv_metrics, mode='a', newline='') as f:\n",
    "        writer_csv = csv.writer(f)\n",
    "        writer_csv.writerow([epoch + 1,\n",
    "                             epoch_train_loss, train_iou, train_prec, train_recall,\n",
    "                             epoch_val_loss, val_iou, val_prec, val_recall,\n",
    "                             round(elapsed_time, 2)])\n",
    "    scheduler.step()\n",
    "    # Checkpoint\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Checkpoint {epoch+1}\")\n",
    "        torch.save(model.state_dict(), f\"/home/antoniocorvino/Projects/BuildingsExtraction/runs/{model_name}/checkpoint_{epoch+1}.pth\")\n",
    "    if earlystop:\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            counter = 0\n",
    "\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            print(f\"No improvement for {early_stop_counter} epoch(s).\")\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            torch.save(model.state_dict(), f\"/home/antoniocorvino/Projects/BuildingsExtraction/runs/{model_name}/best_model.pth\")\n",
    "\n",
    "            break\n",
    "print(f'Total time: {((time.time() - starting_time)/60):.2f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eceb7c-b129-4d81-b593-9e67e494e989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
